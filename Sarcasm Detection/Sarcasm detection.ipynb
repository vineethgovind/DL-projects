{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\", 'is_sarcastic': 0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout,Embedding,LSTM,Bidirectional,Dense,Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "#Read the json file   \n",
    "data = []\n",
    "for line in open('Sarcasm_Headlines_Dataset.json', 'r'):\n",
    "    data.append(json.loads(line)) \n",
    "  \n",
    "# 1st headline\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data is  (26709, 3)\n",
      "   is_sarcastic                                           headline\n",
      "0             0  former versace store clerk sues over secret 'b...\n",
      "columns after dropping article_link Index(['is_sarcastic', 'headline'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#convert list to dataframe\n",
    "\n",
    "df = DataFrame(data,columns=['is_sarcastic','headline','article_link'])\n",
    "print(\"shape of data is \",df.shape)\n",
    "#drop the column article_link\n",
    "df.drop(columns=['article_link'],inplace=True)\n",
    "print(df.head(1))\n",
    "\n",
    "print(\"columns after dropping article_link\",df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_sarcastic                                           headline  col_len\n",
      "0             0  former versace store clerk sues over secret 'b...       78\n",
      "1             0  the 'roseanne' revival catches up to our thorn...       84\n",
      "2             1  mom starting to fear son's web series closest ...       79\n"
     ]
    }
   ],
   "source": [
    "#Get length of each headline and add a column for that\n",
    "df['col_len']=df['headline'].str.len()\n",
    "#1st 2 elements of new dataframe with added column\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X is (26709, 25)\n",
      "Shape of y is (26709, 2)\n",
      "length of vocabulary is  29657\n"
     ]
    }
   ],
   "source": [
    "#Initialize parameter values\n",
    "max_features = 10000\n",
    "maxlen = 25\n",
    "embedding_size = 200\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "\n",
    "\n",
    "tokenizer.fit_on_texts(df.headline)\n",
    "sequences=tokenizer.texts_to_sequences(df.headline)\n",
    "#word indices\n",
    "word_index=tokenizer.word_index\n",
    "#padding\n",
    "X=tf.keras.preprocessing.sequence.pad_sequences(sequences,maxlen=maxlen,padding='post')\n",
    "\n",
    "#convert target column to numpy array\n",
    "y=df['is_sarcastic']\n",
    "\n",
    "#num_classes=len(y.values())\n",
    "y=tf.keras.utils.to_categorical(y,dtype =\"uint8\")\n",
    "#print shape\n",
    "print('Shape of X is',X.shape)\n",
    "print('Shape of y is',y.shape)\n",
    "\n",
    "#number of words\n",
    "num_words = len(word_index) + 1\n",
    "print(\"length of vocabulary is \",num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "#Create embedding matrix\n",
    "EMBEDDING_FILE = 'glove.6B.200d.txt'\n",
    "\n",
    "embedding_dim = 200\n",
    "\n",
    "\n",
    "embeddings = {}\n",
    "for o in open(EMBEDDING_FILE, encoding=\"utf-8\", mode=\"r\"):\n",
    "    word = o.split(\" \")[0]\n",
    "    # print(word)\n",
    "    embd = o.split(\" \")[1:]\n",
    "    embd = np.asarray(embd, dtype='float32')\n",
    "    # print(embd)\n",
    "    embeddings[word] = embd\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "\tembedding_vector = embeddings.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "print(embedding_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\vin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 25, 200)           5931400   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 25, 256)           336896    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 25, 256)           65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 12802     \n",
      "=================================================================\n",
      "Total params: 6,346,890\n",
      "Trainable params: 415,490\n",
      "Non-trainable params: 5,931,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define model\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=maxlen,\n",
    "                            trainable=False)\n",
    "\n",
    "model=tf.keras.Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(units=128 , recurrent_dropout = 0.3 , dropout = 0.3,return_sequences = True)))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18696 samples, validate on 8013 samples\n",
      "Epoch 1/3\n",
      "18696/18696 [==============================] - 64s 3ms/sample - loss: 0.5398 - acc: 0.7216 - val_loss: 0.4464 - val_acc: 0.7886\n",
      "Epoch 2/3\n",
      "18696/18696 [==============================] - 77s 4ms/sample - loss: 0.4285 - acc: 0.7995 - val_loss: 0.3834 - val_acc: 0.8246\n",
      "Epoch 3/3\n",
      "18696/18696 [==============================] - 78s 4ms/sample - loss: 0.3627 - acc: 0.8376 - val_loss: 0.3537 - val_acc: 0.8393\n",
      "Accuracy: 83.93%\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "#fit  the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3 , random_state = 0) \n",
    "history = model.fit(x_train, y_train, batch_size = 128 , validation_data = (x_test,y_test) , epochs = 3)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
