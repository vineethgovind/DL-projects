{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five enteries of the dataframe are:                Short description  \\\n",
      "0                    login issue   \n",
      "1                        outlook   \n",
      "2             cant log in to vpn   \n",
      "3  unable to access hr_tool page   \n",
      "4                   skype error    \n",
      "\n",
      "                                         Description             Caller  \\\n",
      "0  -verified user details.(employee# & manager na...  spxjnwir pjlcoqds   \n",
      "1  \\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...  hmjdrvpb komuaywn   \n",
      "2  \\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...  eylqgodm ybqkwiam   \n",
      "3                      unable to access hr_tool page  xbkucsvz gcpydteq   \n",
      "4                                       skype error   owlgqjme qhcozdfx   \n",
      "\n",
      "  Assignment group  \n",
      "0            GRP_0  \n",
      "1            GRP_0  \n",
      "2            GRP_0  \n",
      "3            GRP_0  \n",
      "4            GRP_0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import splitter\n",
    "import enchant, sys\n",
    "\n",
    "#checking the current working directory\n",
    "os.getcwd()\n",
    "\n",
    "#loading the file\n",
    "filename='input_data.xlsx'\n",
    "data=pd.read_excel(filename)\n",
    "\n",
    "#checking the first five enteries in the file\n",
    "print(\"First five enteries of the dataframe are:\",data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  count unique                top  freq\n",
      "Short description  8492   7481     password reset    38\n",
      "Description        8499   7817                the    56\n",
      "Caller             8500   2950  bpctwhsn kzqsbmtp   810\n",
      "Assignment group   8500     74              GRP_0  3976\n",
      "First 20 enteries of the dataframe are:                                     Short description  \\\n",
      "0                                         login issue   \n",
      "1                                             outlook   \n",
      "2                                  cant log in to vpn   \n",
      "3                       unable to access hr tool page   \n",
      "4                                         skype error   \n",
      "5      unable to log in to engineering tool and skype   \n",
      "6   event criticalhostname companycom the value of...   \n",
      "7   ticket no employment status new nonemployee en...   \n",
      "8                unable to disable add ins on outlook   \n",
      "9                           ticket update on inplant    \n",
      "10  engineering tool says not connected and unable...   \n",
      "11            hr tool site not loading page correctly   \n",
      "12  unable to login to hr tool to sgxqsuojr xwbeso...   \n",
      "13                   user wants to reset the password   \n",
      "14                            unable to open payslips   \n",
      "15                          ticket update on inplant    \n",
      "16                     unable to login to company vpn   \n",
      "17        when undocking pc screen will not come back   \n",
      "18                            erp sid  account locked   \n",
      "19                            unable to sign into vpn   \n",
      "\n",
      "                                          Description Assignment group  \n",
      "0   verified user detailsemployee manager name che...            GRP_0  \n",
      "1   received from hmjdrvpbkomuaywngmailcom hello t...            GRP_0  \n",
      "2   received from eylqgodmybqkwiamgmailcom hi i ca...            GRP_0  \n",
      "3                       unable to access hr tool page            GRP_0  \n",
      "4                                         skype error            GRP_0  \n",
      "5      unable to log in to engineering tool and skype            GRP_0  \n",
      "6   event criticalhostname companycom the value of...            GRP_1  \n",
      "7   ticket no employment status new nonemployee en...            GRP_0  \n",
      "8                unable to disable add ins on outlook            GRP_0  \n",
      "9                           ticket update on inplant             GRP_0  \n",
      "10  engineering tool says not connected and unable...            GRP_0  \n",
      "11            hr tool site not loading page correctly            GRP_0  \n",
      "12  unable to login to hr tool to sgxqsuojr xwbeso...            GRP_0  \n",
      "13                   user wants to reset the password            GRP_0  \n",
      "14                            unable to open payslips            GRP_0  \n",
      "15                          ticket update on inplant             GRP_0  \n",
      "16  received from xyzcompanycom hi i am unable to ...            GRP_0  \n",
      "17        when undocking pc screen will not come back            GRP_3  \n",
      "18                            erp sid  account locked            GRP_0  \n",
      "19                            unable to sign into vpn            GRP_0  \n"
     ]
    }
   ],
   "source": [
    "#various stats of dataframe\n",
    "print(data.describe().transpose())\n",
    "\n",
    "#the Caller column is irrelvant for creating the model\n",
    "data.drop([\"Caller\"],axis=1,inplace=True)\n",
    "\n",
    "#filling in missing values\n",
    "data['Short description'].fillna(value=' ', inplace=True)\n",
    "data['Description'].fillna(value=' ', inplace=True)\n",
    "\n",
    "#data preprocessing\n",
    "\n",
    "def preprocess(text):\n",
    "#1)remove html tags    \n",
    "   soup=BeautifulSoup(text,\"html.parser\")\n",
    "   text=soup.get_text(separator=\"\")\n",
    "    \n",
    "#2) Remove non-ASCII characters\n",
    "   encoded_string = text.encode(\"ascii\", \"ignore\")\n",
    "   text= encoded_string.decode()\n",
    "   \n",
    "#3)lower case    \n",
    "   text=text.lower()\n",
    "   text = ' '.join([w for w in text.split()])\n",
    "#4)remove punctuation       \n",
    "   text = re.sub(r'[^\\w\\s]', '',text) \n",
    "   \n",
    "#5)remove whitespaces\n",
    "   text=\" \".join(text.split())\n",
    " \n",
    "#6)remove  digits  \n",
    "   remove_digits = str.maketrans('', '', digits) \n",
    "   text = text.translate(remove_digits) \n",
    "    \n",
    "#7)remove emails   \n",
    "   text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "   \n",
    "#8)remove hyperlinks\n",
    "   text = re.sub(r'https?:\\/\\/.*\\/\\w*','', text)\n",
    "   \n",
    "#9)remove other characters   \n",
    "   text=text.replace(\"_\",\" \")\n",
    "   \n",
    "\n",
    "   return text   \n",
    "\n",
    "\n",
    "#the preprocessing is applied on the short description and description columns\n",
    "\n",
    "\n",
    "data['Short description']=data['Short description'].apply(preprocess)\n",
    "data['Description']      =data['Description'].apply(preprocess)\n",
    "#verifying the preprocess on sample data\n",
    "print(\"First 20 enteries of the dataframe are:\",data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probleme mit laufwerk z laeusvjo fvaihgpx\n",
      "problems with drive z laeusvjo fvaihgpx \n"
     ]
    }
   ],
   "source": [
    "#language translation\n",
    "\n",
    "from google_trans_new import google_translator #google translate api wasnt working so alternate version was downloaded\n",
    "#https://github.com/lushan88a/google_trans_new  using pip install google_trans_new\n",
    "translator =google_translator()\n",
    "\n",
    "detect =  google_translator().detect\n",
    " \n",
    "def translatetoeng(txt):\n",
    "    if detect(txt)!=  'en':\n",
    "        translation = translator.translate(txt)\n",
    "    else:\n",
    "        translation = txt\n",
    "    return translation\n",
    "#THIS PART OF CODE IS JUST FOR TRYING THE FUNCTION STARTING HERE\n",
    "#trying the detection\n",
    "x=\"हिंदी टायपिंग\"\n",
    "detect(x)\n",
    "#trying the def translatetoeng on a single non english row of the dataframe\n",
    "print((data.iloc[255]['Description']))\n",
    "y=data.iloc[255]['Description']\n",
    "detect(y)#here the output is german\n",
    "#data.iloc[255]['Description']=data.iloc[255]['Description'].apply(translatenoteng)\n",
    "y=translatetoeng(y)\n",
    "print(y)\n",
    "detect(y)#now the output has been converted to english by the function translatetoeng\n",
    "#ENDING HERE\n",
    "#applying the function  on the 2 columns of the dataframe\n",
    "\n",
    "data['Short description']=data['Short description'].apply(translatetoeng)\n",
    "data['Description']=data['Description'].apply(translatetoeng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problems with drive z laeusvjo fvaihgpx \n"
     ]
    }
   ],
   "source": [
    "#checking random entry to check if it has been translated\n",
    "y=data.iloc[255]['Description']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\vin\\anaconda3\\lib\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with drive z\n",
      "with drive z\n"
     ]
    }
   ],
   "source": [
    "#Remove non english words\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "Word = list(set(words.words()))\n",
    "data['Description'] = [\" \".join(w for w in nltk.wordpunct_tokenize(x) \n",
    "                       if w.lower() in Word or not w.isalpha()) \n",
    "                       for x in data['Description']]\n",
    "\n",
    "#testing one a single entry\n",
    "print(data.iloc[255]['Description'])\n",
    "\n",
    "\n",
    "data['Short description'] = [\" \".join(w for w in nltk.wordpunct_tokenize(x) \n",
    "                       if w.lower() in Word or not w.isalpha()) \n",
    "                       for x in data['Short description']]\n",
    "\n",
    "print(data.iloc[255]['Short description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vin\\anaconda3\\lib\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "data['Short description'] = data['Short description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "data['Description'] = data['Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       user manager name checked user name ad reset p...\n",
      "1       received hello team outlook calendar somebody ...\n",
      "2                             received hi cannot log best\n",
      "3                                 unable access tool page\n",
      "4                                                   error\n",
      "                              ...                        \n",
      "8495      received good afternoon sent mail please advise\n",
      "8496                                      telephony issue\n",
      "8497                                       password reset\n",
      "8498    unable access machine finish drawers adjustmen...\n",
      "8499              Different program cannot several . area\n",
      "Name: Description, Length: 8500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#checking one column after stopword removal\n",
    "print(data['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable create print cant post detail information see attachment\n",
      "please provide following order number material item number warehouse location plant issue description error message see attachment\n",
      "unable create print cant post detail information see attachment please provide following order number material item warehouse location plant issue description error message\n"
     ]
    }
   ],
   "source": [
    "#merging  the 2 preprocessed columns to a single column without duplicate words\n",
    "data['Combined description'] = data['Short description'] .map(str) + ' ' +  data['Description'].map(str)\n",
    "                    \n",
    "data['Combined description'] = data['Combined description'].apply(lambda x: ' '.join(pd.unique(x.split()))) \n",
    "   \n",
    "#testing on single entry\n",
    "print(data.iloc[279]['Short description'])\n",
    "print(data.iloc[279]['Description'])\n",
    "print(data.iloc[279]['Combined description'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand contractions\n",
    "contractions_dict = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"didnt\": \"did not\",\n",
    "\"doesnt\": \"does not\",\n",
    "\"thats\": \"that is\",\n",
    "\"wasnt\": \"was not\",\n",
    "\"weren\": \"were not\",\n",
    "\"theyre\": \"there\",\n",
    "\"dont\": \"do not\",\n",
    "\"cant\": \"cannot\",\n",
    "\"arent\": \"are not\",\n",
    "\"whats\": \"what is\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "  def replace(match):\n",
    "    return contractions_dict[match.group(0)]\n",
    "  return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions in the reviews\n",
    "data['Combined description']=data['Combined description'].apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller \n",
    "spell =Speller('en')       #Speller(fast=True) for faster but less accurate correctiondata\n",
    "data['Combined description']=[' '.join([spell(i) for i in x.split()]) for x in data['Combined description']\n",
    "                             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional preprocessing\n",
    "import string\n",
    "def preprocess(text):\n",
    " text=text.replace(\" vas \",\" \")\n",
    " text=text.replace(\" ae \",\" \")\n",
    " text=text.replace(\"theres \",\"there is \")\n",
    " text=text.replace(\"wouldnt \",\"would not \")\n",
    " text=text.replace(\" amar \",\" \")\n",
    " text=text.replace(\" ted \",\" \")\n",
    " text=text.replace(\" sam \",\" \")\n",
    " text=text.replace(\" marc \",\" \")\n",
    " text=text.replace(\" ross \",\" \")\n",
    " text=text.replace(\"maint \",\"maintenance \")\n",
    " text=text.replace(\" ess\",\" \")\n",
    " text=text.replace(\"roanoke \",\" \")\n",
    " text=text.replace(\"futbol \",\" \")\n",
    " text=text.replace(\" shi \",\" \")\n",
    " text=text.replace(\" pur \",\" \")\n",
    " text=text.replace(\" wy \",\" \")\n",
    " text=text.replace(\" wy\",\" \")\n",
    " text=text.replace(\" ce \",\" \")\n",
    " text=text.replace(\" alt \",\" alternate \")\n",
    " text=text.replace(\" div \",\" division \")\n",
    " text=text.replace(\" tam \",\" team \")\n",
    " text=text.replace(\"shouldnt \",\" should not \")\n",
    " text=text.replace(\"haventnt \",\" have not \")\n",
    " text=text.replace(\"serrata \",\" \")\n",
    " text=text.replace(\" ko \",\" \")\n",
    " text=text.replace(\" sab \",\" \")\n",
    " text=text.replace(\" fe \",\" \")\n",
    " text=text.replace(\" pu \",\" \")\n",
    " text=text.replace(\" po \",\" \")\n",
    " text=text.replace(\" das \",\" \")\n",
    " text=text.replace(\" mio \",\" \")\n",
    " text=text.replace(\" alfa \",\" \")\n",
    " text=text.replace(\"squadra \",\" \")\n",
    " text=text.replace(\" ora \",\" \")\n",
    " text=text.replace(\" nt \",\" want \")\n",
    " text=text.replace(\" nt\",\" want \")\n",
    " text=text.replace(\" dow\",\" down\")\n",
    " text=text.replace(\" th \",\" \")\n",
    " text=text.replace(\" se \",\" \")\n",
    " text=text.replace(\" li \",\" \")\n",
    " text=text.replace(\" sal \",\" \")\n",
    " text=text.replace(\" os \",\" \")\n",
    " text=text.replace(\" u \",\" \")\n",
    " text=text.replace(\" bu \",\" \")\n",
    " text=text.replace(\" fu \",\" \")\n",
    " text=text.replace(\" mein \",\" \")\n",
    " text=text.replace(\" ess \",\" \")\n",
    " text=text.replace(\" ist \",\" \")\n",
    " text=text.replace(\" ewe \",\" \")\n",
    " text=text.replace(\" poe \",\" power \")\n",
    " text=text.replace(\" rm\",\"warm\")\n",
    " text=text.replace(\" rm \",\"warn\")\n",
    " text=text.replace(\" lan \",\" \")\n",
    " text=text.replace(\" ug \",\" \")\n",
    " text=text.replace(\" wa \",\" \")\n",
    " text=text.replace(\" wo \",\" \")\n",
    " text=text.replace(\" ie\",\" \")\n",
    " text=text.replace(\" ie \",\" \")\n",
    " text=text.replace(\" st \",\" \")\n",
    " text=text.replace(\" ey \",\" \")\n",
    " text=text.replace(\" mo \",\" \")\n",
    " text=text.replace(\" mir \",\" \")\n",
    " text=text.replace(\"aw \",\" \")\n",
    " #text=text.replace(\"ie \",\" \")\n",
    " text=text.replace(\" oe \",\" \")\n",
    " text=text.replace(\" aa \",\" \")\n",
    " text=text.replace(\"sa \",\" \")\n",
    " text=text.replace(\" si \",\" \")\n",
    " text=text.replace(\" das \",\" \")\n",
    " text=text.replace(\" dob \",\" \")\n",
    " text=text.replace(\" bisch \",\" \")\n",
    " text=text.replace(\" iso \",\" \")\n",
    " text=text.replace(\" och \",\" \")\n",
    " text=text.replace(\"sao \",\" \")\n",
    " text=text.replace(\"eu \",\"european union \")\n",
    " text=text.replace(\"withdr\",\"withdraw \")\n",
    " text=text.replace(\"serverdown\",\" server down \")\n",
    " text=text.replace(\"timecard\",\" time  card \")\n",
    " text=text.replace(\" rning\",\"warning \")\n",
    " text=text.replace(\"cleanup\",\"clean up \")\n",
    " text=text.replace(\" vida \",\" via \")\n",
    " text=text.replace(\" proto \",\"  \")\n",
    " text=text.replace(\" u \",\"  \")\n",
    " text=text.replace(\" fi \",\"  \")\n",
    " text=text.replace(\" campo \",\" \")\n",
    " text=text.replace(\" corp \",\" \")\n",
    " text=text.replace(\"dup \",\" \")\n",
    " text=text.replace(\" ar \",\" \")\n",
    " text=text.replace(\"brock \",\" \")\n",
    " text=text.replace(\" hanna \",\" \")\n",
    " text=text.replace(\"hanna \",\" \")\n",
    " text=text.replace(\" sherlock \",\" \")\n",
    " text=text.replace(\" wi fi \",\" wifi \")\n",
    " text=text.replace(\" sud \",\" \")\n",
    " text=text.replace(\" anyways \",\" anyway \")\n",
    " text=text.replace(\" anyways\",\" anyway \")\n",
    " text=text.replace(\" bom \",\" \")\n",
    " text=text.replace(\" curr \",\" current \")\n",
    " text=text.replace(\" center pam\",\" center \")   \n",
    " text=text.replace(\" noncompliance\",\" non compliance\")\n",
    " text=text.replace(\" intercompany \",\" inter company \")\n",
    " text=text.replace(\" wi \",\" wifi \")\n",
    " text=text.replace(\" herman \",\" \")\n",
    " text=text.replace(\" sind \",\" \")\n",
    " text=text.replace(\" neal \",\" \")\n",
    " text=text.replace(\" awa \",\" \")\n",
    " text=text.replace(\" wir \",\" \")\n",
    " text=text.replace(\" rita \",\" \")\n",
    " text=text.replace(\" didnt \",\" did not \")\n",
    " text=text.replace(\"ess portal \",\" portal \") \n",
    " text=text.replace(\" whats \",\" what is \") \n",
    " text=text.replace(\" thats \",\" that is \")\n",
    " text=text.replace(\" arent \",\" are not \")\n",
    " text=text.replace(\" wasnt \",\" was not \")\n",
    " text=text.replace(\"parlbox\",\"mailbox \")\n",
    " text=text.replace(\"ess login \",\" login \")\n",
    " text=text.replace(\"ess portal \",\" portal \")\n",
    " text=text.replace(\"ess expense \",\" expense \") \n",
    " text=text.replace(\"ess password \",\" password \")  \n",
    " text=text.replace(\" till st\",\" till \")\n",
    " #text=text.replace(\" tool st \",\" tool \")\n",
    " text=text.replace(\"fi two \",\" two \")\n",
    " text=text.replace(\"ess portal \",\" portal \") \n",
    " text=text.replace(\"ess access \",\" access \")    \n",
    " text=text.replace(\"ess site \",\" site \") \n",
    " text=text.replace(\" login ess\",\" login \")\n",
    " text=text.replace(\"ko assign \",\" assign \")  \n",
    " text=text.replace(\" period til \",\" period till \") \n",
    " text=text.replace(\"write ce\",\" write manager\")\n",
    " text=text.replace(\"since th\",\" since \") \n",
    " #text=text.replace(\"since st\",\" since \") \n",
    " text=text.replace(\"wi access \",\"wifi access \") \n",
    " text=text.replace(\" bis wird\",\" \") \n",
    " text=text.replace(\" used si\",\" used \") \n",
    " text=text.replace(\" possible last th \",\" possible last \")\n",
    " text=text.replace(\"ey consultant\",\" consultant \") \n",
    " text=text.replace(\"approval ce\",\" approval \") \n",
    " text=text.replace(\"since st \",\" since \")\n",
    " text=text.replace(\"pur wrong \",\" wrong \") \n",
    " text=text.replace(\" rie start \",\" start \") \n",
    " text=text.replace(\"dob report \",\"report \")\n",
    " text=text.replace(\" addr login \",\" address login \") \n",
    " text=text.replace(\" room fe\",\" room \")\n",
    " text=text.replace(\" futbol\",\" football \") \n",
    " text=text.replace(\" current st \",\" current\") \n",
    " text=text.replace(\" examine nat \",\" examine \") \n",
    " text=text.replace(\"synchro \",\" synchronise \") \n",
    " text=text.replace(\" delete th\",\" delete \") \n",
    " text=text.replace(\" global naa \",\" global \") \n",
    " text=text.replace(\"mio cannot \",\" cannot \") \n",
    " text=text.replace(\"fe does \",\" does \") \n",
    " text=text.replace(\" went colin \",\" went \") \n",
    " text=text.replace(\" user sar r \",\" user \") \n",
    " text=text.replace(\" hi ti \",\" \") \n",
    " text=text.replace(\" sao campo \",\"  \") \n",
    " text=text.replace(\" sao campo\",\"  \") \n",
    " text=text.replace(\" havent \",\" have not \")    \n",
    " text=text.replace(\" pinto \",\"  \") \n",
    " text=text.replace(\" system st\",\" system  \") \n",
    " text=text.replace(\" guest wirel \",\" guest wireless  \") \n",
    " text=text.replace(\" pax \", \" \") \n",
    " text=text.replace(\" un kwown \",\" unknown \") \n",
    " text=text.replace(\"lan n \",\" lan \") \n",
    " text=text.replace(\"ted update \",\" wanted update  \") \n",
    " text=text.replace(\" pam ferreira \",\"  \") \n",
    " text=text.replace(\"ora internal \",\" internal  \") \n",
    " text=text.replace(\" empty acc \",\" empty  \") \n",
    " text=text.replace(\" acc \",\" access \")\n",
    " text=text.replace(\" ferreira \",\" \")\n",
    " text=text.replace(\" show te \",\" show the  \") \n",
    " text=text.replace(\" gen ing \",\" \") \n",
    " text=text.replace(\" cutoff \",\" cut off  \") \n",
    " text=text.replace(\" fill rate th\",\" fill rate  \") \n",
    " text=text.replace(\" printed sie \",\" printed \") \n",
    " text=text.replace(\"working campo \",\" working  \") \n",
    " text=text.replace(\"working campo\",\" working  \")    \n",
    " text=text.replace(\" addr \",\" \")    \n",
    " text=text.replace(\" delivery hoi \",\" delivery \") \n",
    " text=text.replace(\"unable acc \",\" unable access \") \n",
    " text=text.replace(\" see sny \",\" see \") \n",
    " text=text.replace(\"wy printer received \",\" printer received \") \n",
    " text=text.replace(\"update several th\",\" update several \") \n",
    " text=text.replace(\" log int access \",\" log access \")\n",
    " text=text.replace(\" joe \",\"  \") \n",
    " text=text.replace(\" na \",\"  \")    \n",
    " text=text.replace(\" andstill \",\" and still  \") \n",
    " text=text.replace(\"ess kiosk \",\" kiosk \")\n",
    " text=text.replace(\" need active st\",\" need active status \") \n",
    " text=text.replace(\" tool opped \",\" tool stopped \")  \n",
    " text=text.replace(\" assembly sha \",\" assembly \")\n",
    " text=text.replace(\" campo\",\" \") \n",
    " text=text.replace(\" since atus \",\" since status \") \n",
    " text=text.replace(\" amy \",\" \") \n",
    " text=text.replace(\" department tha \",\" department \") \n",
    " text=text.replace(\" possible last th\",\" possible last \") \n",
    " text=text.replace(\" retiring company th\",\" retiring company \")\n",
    " text=text.replace(\" downnn\",\" down\")\n",
    " text=text.replace(\"intercompany \",\" inter company \")\n",
    " text=text.replace(\"ana call \",\" call \") \n",
    " text=text.replace(\"setup machine wa\",\" setup machine \")\n",
    " text=text.replace(\"drum south sa\",\" drum south \")\n",
    " text=text.replace(\"ar since\",\" since \")\n",
    " text=text.replace(\"wi access \",\" wifi access \")\n",
    " text=text.replace(\" extend current st\",\" extend current status \")\n",
    " #text=text.replace(\" dialin \",\" dialing \")    \n",
    " return text\n",
    "\n",
    "data[\"Combined description\"]= data[\"Combined description\"].apply(preprocess)\n",
    "#drop empty columns(some columns became empty after preprocessing)\n",
    "nan_value = float(\"NaN\")\n",
    "data.replace(\"\", nan_value, inplace=True)\n",
    "\n",
    "#drop the 2 description columns as all the information is there in the combined description columnn\n",
    "data.drop([\"Short description\",\"Description\"],axis=1,inplace=True)\n",
    "#drop other columns with no info\n",
    "data.drop([2932],axis=0,inplace=True)\n",
    "data.drop([2848],axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle data\n",
    "import pickle         \n",
    "data.to_pickle('preprocesseddata.pkl')\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('pro_trans_inputv4.xlsx', engine='xlsxwriter')\n",
    "data.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()                        \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
